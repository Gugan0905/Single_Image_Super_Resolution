{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CS7180 - Advanced Perception\n",
        "\n",
        "Image Enhancement Proj 1\n",
        "\n",
        "20th September 2023\n",
        "\n",
        "By\n",
        "\n",
        "> Anirudh Muthuswamy, NUID - 002783250\n",
        "\n",
        "\n",
        "> Gugan Kathiresan, NUID - 002756523\n",
        "\n"
      ],
      "metadata": {
        "id": "KK0RQTTCcpHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements - Libraries and Module Installation"
      ],
      "metadata": {
        "id": "_nREqHHAZ9QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify\n",
        "!pip install torchviz\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGc2R8ZksDnD",
        "outputId": "a42c90b7-1d4a-4ed1-da20-3b3d1bde5c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.23.5)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4130 sha256=297c068b1d3e79b3126c9265a1b2a9b70ebcc86a53c222e4fde994328d941903\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "2BloTAlnaDza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import patchify\n",
        "\n",
        "import pandas as pd\n",
        "import glob as glob\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "plt.style.use('ggplot')\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchviz import make_dot\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "htyjmlrr-0lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "j6tSKJTUaLRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkpp0kTir4Tv",
        "outputId": "7f54f619-f37b-40d5-d690-f0340ee9d42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare files"
      ],
      "metadata": {
        "id": "VJ1xMGjkaIrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzipping the DIV2k2017 Dataset"
      ],
      "metadata": {
        "id": "mS3Hkg6aaNmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Copy of DIV2K2017.zip'"
      ],
      "metadata": {
        "id": "rd4ht2iDsZam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Patches from the High Resolution images.\n",
        "\n",
        "These patches are basically sub-images of the original image.\n",
        "\n",
        "*(Serves the aim of super-resolution:\n",
        " picking out small regions of the original image, blowing it up and improving the resolution on that.)*"
      ],
      "metadata": {
        "id": "Pbqf5Hk6aZQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Function to store the high resolution patches, i.e, sub-images in the specified folder.\n",
        " High resolution images are simple patches of the original image of size 32x32 moved over the\n",
        " original image with a stride of 14.'''\n",
        "\n",
        "def create_high_res_patches(patch_path, patch_size, stride, image_paths, images):\n",
        "\n",
        "  os.makedirs(patch_path, exist_ok = True)\n",
        "\n",
        "  print(\"Number of images in directory:\", len(image_paths))\n",
        "\n",
        "  breaktime = 0\n",
        "  for image_path in image_paths:\n",
        "      breaktime += 1\n",
        "      ''' Obtaining the image'''\n",
        "      input_image = Image.open(image_path)\n",
        "      image_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
        "      print(\" Image name:\", image_name)\n",
        "\n",
        "      ''' Passing to patchify function'''\n",
        "      high_res_patches = patchify.patchify(np.array(input_image), patch_size, stride)\n",
        "      print(\" \\tImage size:\", high_res_patches.shape)\n",
        "\n",
        "      '''Reading the patches generated and saving individually'''\n",
        "      counter = 0\n",
        "      for i in range(high_res_patches.shape[0]):\n",
        "          for j in range(high_res_patches.shape[1]):\n",
        "              counter +=1\n",
        "              patch = high_res_patches[i, j, 0, :, :, :]\n",
        "              patch = cv2.cvtColor(patch, cv2.COLOR_RGB2BGR)\n",
        "              cv2.imwrite(f\"{patch_path}/{image_name}_{counter}.png\",patch)\n",
        "\n",
        "      ''' \"breaktime\" Used to control the number of images in our dataset.\n",
        "       To use the full dataset set the breaktime to the number of images in the dataset.\n",
        "       For testing purposes, we chose to pick only 5 images, hence images = 5.'''\n",
        "\n",
        "      if breaktime == images:\n",
        "        break"
      ],
      "metadata": {
        "id": "575iXJ78tJ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Function to store the low resolution patches, i.e, sub-images that are\n",
        " generated from the high res patches.\n",
        " To acheive this we apply bilinear interpolation to high res patches and\n",
        " store the low res patches in a different directory.'''\n",
        "\n",
        "def create_low_res_patches(patch_path, patch_size, stride, image_paths, images):\n",
        "\n",
        "  os.makedirs(patch_path, exist_ok = True)\n",
        "  breaktime = 0\n",
        "\n",
        "  for image_path in image_paths:\n",
        "      breaktime += 1\n",
        "      ''' Obtaining the image'''\n",
        "      input_image = Image.open(image_path)\n",
        "      image_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
        "      print(\" Image name:\", image_name)\n",
        "\n",
        "      ''' Passing to patchify function'''\n",
        "      high_res_patches = patchify.patchify(np.array(input_image), patch_size, stride)\n",
        "      print(\" \\tImage size:\", high_res_patches.shape)\n",
        "\n",
        "      '''Reading the patches generated, applying Guassian Blur to reduce the quality,\n",
        "        downsizing by half, resizing it back to the same size using bicubic interpolation\n",
        "        and finally saving individually'''\n",
        "      counter = 0\n",
        "      for i in range(high_res_patches.shape[0]):\n",
        "          for j in range(high_res_patches.shape[1]):\n",
        "              counter = counter + 1\n",
        "              patch = high_res_patches[i,j,0,:,:,:]\n",
        "              patch = cv2.cvtColor(patch, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "              h = 32\n",
        "              w = 32\n",
        "\n",
        "              # patch_blurred = cv2.GaussianBlur(patch,(3,3),0)\n",
        "              low_res_patch = cv2.resize(patch, (int(h*0.5), int(w*0.5)), interpolation=cv2.INTER_CUBIC)\n",
        "              upscaled_patch = cv2.resize(low_res_patch, (h,w), interpolation=cv2.INTER_CUBIC)\n",
        "              cv2.imwrite(f\"{patch_path}/{image_name}_{counter}.png\",upscaled_patch)\n",
        "\n",
        "      if breaktime == images:\n",
        "        break"
      ],
      "metadata": {
        "id": "nq6wCgLnvGYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stride = 14\n",
        "patch_size = (32, 32, 3)\n",
        "input_path = \"DIV2K2017/DIV2K/DIV2K_train_HR\"\n",
        "image_extension = 'png'\n",
        "image_paths = []\n",
        "image_paths.extend(glob.glob(os.path.join(input_path, f'*.{image_extension}')))\n",
        "\n",
        "print(\"Creating High Res Patches...\")\n",
        "create_high_res_patches(\"high_res_patches_5_Imgs\", patch_size, stride, image_paths, 5)\n",
        "print('')\n",
        "\n",
        "print(\"Creating Low Res Patches...\")\n",
        "create_low_res_patches(\"low_res_patches_5_Imgs\", patch_size, stride, image_paths, 5)\n",
        "print('')"
      ],
      "metadata": {
        "id": "Pv-1Jh4B4r2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bead3bb-4dbf-4f14-e311-6f833f0ab318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating High Res Patches...\n",
            "Number of images in directory: 900\n",
            " Image name: 0840\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0506\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0317\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0886\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0445\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            "\n",
            "Creating Low Res Patches...\n",
            " Image name: 0840\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0506\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0317\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0886\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            " Image name: 0445\n",
            " \tImage size: (95, 144, 1, 32, 32, 3)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Function to store the low resolution patches, i.e, sub-images that are\n",
        " generated from the high res patches.\n",
        " To acheive this we apply bilinear interpolation to high res patches and\n",
        " store the low res patches in a different directory.'''\n",
        "\n",
        "def create_low_res_Images(low_res_image_path, image_paths, images):\n",
        "\n",
        "  os.makedirs(low_res_image_path, exist_ok = True)\n",
        "  breaktime = 0\n",
        "\n",
        "  for image_path in image_paths:\n",
        "      breaktime += 1\n",
        "      ''' Obtaining the image'''\n",
        "      print(image_path)\n",
        "      input_image = cv2.imread(image_path)\n",
        "      image_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
        "      h = input_image.shape[1]\n",
        "      w = input_image.shape[0]\n",
        "\n",
        "      # image_blurred = cv2.GaussianBlur(input_image,(3,3),0)\n",
        "      low_res_image = cv2.resize(input_image, (int(h*0.5), int(w*0.5)), interpolation=cv2.INTER_CUBIC)\n",
        "      upscaled_image = cv2.resize(low_res_image, (h,w), interpolation=cv2.INTER_CUBIC)\n",
        "      cv2.imwrite(f\"{low_res_image_path}/{image_name}.png\",upscaled_image)\n",
        "\n",
        "      if breaktime == images:\n",
        "        break"
      ],
      "metadata": {
        "id": "tDle1YwhQdXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating Low Res Images...\")\n",
        "create_low_res_Images(\"low_res_Images\", image_paths, 50)\n",
        "# create_low_res(\"low_res_patches_50_Imgs\", patch_size, stride, image_paths, 50)\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFsQRUcARNqu",
        "outputId": "ba63f838-e473-456f-e454-5c12df570024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Low Res Images...\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0840.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0506.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0317.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0886.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0445.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0479.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0282.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0586.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0070.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0612.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0882.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0781.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0327.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0817.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0716.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0391.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0396.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0477.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0118.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0602.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0898.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0534.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0095.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0303.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0255.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0181.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0436.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0558.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0536.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0441.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0199.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0369.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0172.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0657.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0776.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0005.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0622.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0178.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0802.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0304.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0373.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0655.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0708.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0004.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0124.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0514.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0502.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0084.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0299.png\n",
            "DIV2K2017/DIV2K/DIV2K_train_HR/0569.png\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "Te81zoEwa5Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Function to get patched dataset details and generate a csv file for the train data.'''\n",
        "\n",
        "def get_hrlr_split_patches(hr_path, lr_path, train_csv_path):\n",
        "  print(\"Number of high res patches =\", len(os.listdir(hr_path)))\n",
        "  print(\"Number of low res patches =\", len(os.listdir(lr_path)))\n",
        "\n",
        "  y_filenames = os.listdir(hr_path)\n",
        "  y_filenames = sorted(y_filenames)\n",
        "  y_filenames = [hr_path + file for file in y_filenames]\n",
        "\n",
        "  x_filenames = os.listdir(lr_path)\n",
        "  x_filenames = sorted(x_filenames)\n",
        "  x_filenames = [lr_path + file for file in x_filenames]\n",
        "\n",
        "  ''' Adding all x filepaths == low res patches and y filepaths == high res patches to a dataframe.'''\n",
        "  data = pd.DataFrame({'x_filepath':x_filenames, 'y_filepath':y_filenames})\n",
        "  data_randomized = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "  data_randomized.to_csv(train_csv_path, index = False)\n"
      ],
      "metadata": {
        "id": "NNt4VkFVa_VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_hrlr_split_patches('/content/high_res_patches_5_Imgs/', '/content/low_res_patches_5_Imgs/',\n",
        "                'train_data_5_Imgs_patched.csv')"
      ],
      "metadata": {
        "id": "RRB102zJifOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f4e629-f029-41c0-e8f6-3c4e4c014f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of high res patches = 68400\n",
            "Number of low res patches = 68400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating test csv for validating model with 50 low resolution images\n",
        "\n",
        "''' Function to get low res Image dataset details and generate a csv file for the test split.'''\n",
        "\n",
        "def get_hrlr_split_Images(hr_path, lr_path, csv_path):\n",
        "  print(\"Number of high res patches =\", len(os.listdir(hr_path)))\n",
        "  print(\"Number of low res patches =\", len(os.listdir(lr_path)))\n",
        "\n",
        "  y_filenames = os.listdir(hr_path)[0:50]\n",
        "  y_filenames = sorted(y_filenames)\n",
        "  y_filenames = [hr_path + '/' + file for file in y_filenames]\n",
        "  print(y_filenames[:5])\n",
        "\n",
        "  x_filenames = os.listdir(lr_path)\n",
        "  x_filenames = sorted(x_filenames)\n",
        "  x_filenames = [lr_path + '/' + file for file in x_filenames]\n",
        "\n",
        "  ''' Adding all x filepaths == low res patches and y filepaths == high res patches to a dataframe.'''\n",
        "  data = pd.DataFrame({'x_filepath':x_filenames, 'y_filepath':y_filenames})\n",
        "  data_randomized = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "  data_randomized.to_csv(csv_path, index = False)\n",
        "\n",
        "\n",
        "get_hrlr_split_Images('/content/DIV2K2017/DIV2K/DIV2K_train_HR', '/content/low_res_Images',\n",
        "                'test_data_50_Imgs.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCbcPnIlUa9A",
        "outputId": "98d6b6c9-9d6c-48e3-a05e-fbbbe0fde15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of high res patches = 900\n",
            "Number of low res patches = 50\n",
            "['/content/DIV2K2017/DIV2K/DIV2K_train_HR/0004.png', '/content/DIV2K2017/DIV2K/DIV2K_train_HR/0005.png', '/content/DIV2K2017/DIV2K/DIV2K_train_HR/0070.png', '/content/DIV2K2017/DIV2K/DIV2K_train_HR/0084.png', '/content/DIV2K2017/DIV2K/DIV2K_train_HR/0095.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Definition"
      ],
      "metadata": {
        "id": "ukzQX-bLaGSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "'''Class to perform the necessary initial preprocessing and to call a dataset from a csv file (standard pytorch dataset).\n",
        " Performs normalization and creates a dataset tensor for images and labels separately'''\n",
        "\n",
        "class SRCNNDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    ''' returns a tensor for the images and labels of the datasets (low res and high res iamges respectively)\n",
        "     Performs normalization and transpose that brings it to the requirements of a tensor.'''\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.data.iloc[idx, 0]).convert('RGB')\n",
        "        label = Image.open(self.data.iloc[idx, 1]).convert('RGB')\n",
        "\n",
        "        image = np.array(image, dtype=np.float32)\n",
        "        label = np.array(label, dtype=np.float32)\n",
        "\n",
        "        image /= 255.\n",
        "        label /= 255.\n",
        "\n",
        "        image = image.transpose([2, 0, 1])\n",
        "        label = label.transpose([2, 0, 1])\n",
        "\n",
        "        return (\n",
        "            torch.tensor(image, dtype=torch.float),\n",
        "            torch.tensor(label, dtype=torch.float)\n",
        "        )"
      ],
      "metadata": {
        "id": "bm9aeO6G8xOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Prepare the datasets by creating objects of the SRCNNDataset class that was previously defined'''\n",
        "def get_datasets(train_csv_file,valid_csv_file):\n",
        "\n",
        "    dataset_train = SRCNNDataset(csv_file=train_csv_file)\n",
        "    dataset_valid = SRCNNDataset(csv_file=valid_csv_file)\n",
        "\n",
        "    return dataset_train, dataset_valid\n",
        "\n",
        "''' Prepare the dataloader using the Dataloader torch library'''\n",
        "def get_dataloaders(dataset_train, dataset_valid):\n",
        "    train_loader = DataLoader(\n",
        "        dataset_train,\n",
        "        batch_size=256,\n",
        "        shuffle=True\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        dataset_valid,\n",
        "        batch_size=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "_3pLPulMMEwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "DnyoRx45a1bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Class to define the base SRCNN Model from the source paper inspiration.\n",
        " Uses 3 convolutional layers with filter kernel sizes and channels as suggested by the paper.\n",
        "\n",
        " C. Dong, C. C. Loy, K. He, and X. Tang, “Learning a Deep Convolutional Network\n",
        " for Image Super-Resolution,” Computer Vision – ECCV 2014, pp. 184–199, 2014,\n",
        " doi: https://doi.org/10.1007/978-3-319-10593-2_13.'''\n",
        "\n",
        "class CustomConvLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomConvLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = 64, out_channels=32, kernel_size=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels = 32, out_channels=3, kernel_size=5, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        return self.conv3(x)"
      ],
      "metadata": {
        "id": "31z8NOiYSiWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' SRCNN Model v2.\n",
        " Includes some modifications made by Anirudh + Gugan.\n",
        " The ideology behind the approach originates from the basic task of creating a wider but not-heavy network.\n",
        " There are four parallel initial convolutional layers that vary in kernel size. These extract different perspectives\n",
        " of different patches from the upsampled low res input (similar to the base SRCNN but with different filter sizes).\n",
        "\n",
        " These patches represent different features maps highlight unique information from the input image for further operations.\n",
        " By applying a wider network with parallel layers, which are later concated to perform non-linear mapping,\n",
        " our goal is to pickup features that were possibly not picked up by previous single layer filter sizes.\n",
        " '''\n",
        "\n",
        "class CustomConvLayer2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomConvLayer2, self).__init__()\n",
        "        self.conv_input1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
        "        self.conv_input2 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv_input3 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=5, padding=2)\n",
        "        self.conv_input4 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=7, padding=3)\n",
        "\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = 256, out_channels=32, kernel_size=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels = 32, out_channels=3, kernel_size=5, padding=2)\n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.conv_input1(x))\n",
        "        out2 = F.relu(self.conv_input2(x))\n",
        "        out3 = F.relu(self.conv_input3(x))\n",
        "        out4 = F.relu(self.conv_input4(x))\n",
        "\n",
        "        x = torch.cat((out1, out2, out3, out4), 1)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        return self.conv3(x)"
      ],
      "metadata": {
        "id": "1SASgC2_qSW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Utilities"
      ],
      "metadata": {
        "id": "pvS8QbN6fpet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "m-4v1FwJWzzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Implementing the PSNR Metric'''\n",
        "\n",
        "def psnr(label, outputs, max_val = 1):\n",
        "  # Formula for psnr = 20 * log(Max pixel value) - 10 * log(MSE)\n",
        "\n",
        "  label = label.cpu().detach().numpy()\n",
        "  outputs = outputs.cpu().detach().numpy()\n",
        "\n",
        "  diff = outputs - label\n",
        "  rmse = math.sqrt(np.mean((diff)**2))\n",
        "  if rmse == 0:\n",
        "    return 100\n",
        "  else:\n",
        "    return 20 * math.log10(max_val / rmse)"
      ],
      "metadata": {
        "id": "NRPh1LQc-1rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Function to save graphs that track the training and validaton loss and psnr'''\n",
        "\n",
        "\n",
        "\n",
        "def save_plot(train_loss, val_loss, train_psnr, val_psnr, output_dir):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok = True)\n",
        "    # Loss plots.\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(train_loss, color='orange', label='train loss')\n",
        "    plt.plot(val_loss, color='red', label='validataion loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{output_dir}/loss.png')\n",
        "    plt.close()\n",
        "    # PSNR plots.\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(train_psnr, color='green', label='train PSNR dB')\n",
        "    plt.plot(val_psnr, color='blue', label='validataion PSNR dB')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{output_dir}/psnr.png')\n",
        "    plt.close()\n",
        "\n",
        "'''Function to save a model to a torch pth file'''\n",
        "\n",
        "def save_model_state(model, output_dir):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok = True)\n",
        "    # save the model to disk\n",
        "    print('Saving model...')\n",
        "    torch.save(model.state_dict(), f'{output_dir}/model.pth')\n",
        "\n",
        "'''Function to save a model checkpoint and remove any previous model checkpoints\n",
        "if existing.Useful to pickup and continue training'''\n",
        "\n",
        "def save_model(epochs, model, optimizer, criterion, output_dir):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok = True)\n",
        "    torch.save({\n",
        "                'epoch': epochs+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, f'{output_dir}/model_ckpt.pth')\n",
        "\n",
        "\n",
        "'''Function to save the validation reconstructed images.'''\n",
        "\n",
        "def save_validation_results(outputs, epoch, batch_iter, output_dir):\n",
        "\n",
        "    os.makedirs(output_dir+'/valid_results', exist_ok = True)\n",
        "    save_image(\n",
        "        outputs,\n",
        "        f'{output_dir}/valid_results/val_sr_{epoch}_{batch_iter}.png'\n",
        "    )"
      ],
      "metadata": {
        "id": "t8RmwMAdirOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Implement the SRCNN v2 by Anirudh + Gugan'''\n",
        "\n",
        "model = CustomConvLayer2()\n",
        "model = model.to(device = 'cuda')\n",
        "summary(model, (3, 32, 32))\n",
        "\n",
        "dummy_input = torch.randn(1,3, 32, 32)\n",
        "dummy_input = dummy_input.to(device = 'cuda')\n",
        "\n",
        "output = model(dummy_input)\n",
        "\n",
        "graph = make_dot(output, params=dict(model.named_parameters()))\n",
        "graph.render(filename='model_graph')\n",
        "\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "5QEq3K93rPi0",
        "outputId": "cd7ee11b-6025-4cee-ac79-e6c967303eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]          15,616\n",
            "            Conv2d-2           [-1, 64, 32, 32]           1,792\n",
            "            Conv2d-3           [-1, 64, 32, 32]           4,864\n",
            "            Conv2d-4           [-1, 64, 32, 32]           9,472\n",
            "            Conv2d-5           [-1, 32, 32, 32]           8,224\n",
            "            Conv2d-6            [-1, 3, 32, 32]           2,403\n",
            "================================================================\n",
            "Total params: 42,371\n",
            "Trainable params: 42,371\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.27\n",
            "Params size (MB): 0.16\n",
            "Estimated Total Size (MB): 2.45\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"864pt\" height=\"386pt\"\n viewBox=\"0.00 0.00 864.00 386.35\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1.33 1.33) rotate(0) translate(4 508)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-508 1141,-508 1141,4 -4,4\"/>\n<!-- 135893253556960 -->\n<g id=\"node1\" class=\"node\">\n<title>135893253556960</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"1021,-31 914,-31 914,0 1021,0 1021,-31\"/>\n<text text-anchor=\"middle\" x=\"967.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 3, 32, 32)</text>\n</g>\n<!-- 135893647581936 -->\n<g id=\"node2\" class=\"node\">\n<title>135893647581936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1036,-86 899,-86 899,-67 1036,-67 1036,-86\"/>\n<text text-anchor=\"middle\" x=\"967.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647581936&#45;&gt;135893253556960 -->\n<g id=\"edge36\" class=\"edge\">\n<title>135893647581936&#45;&gt;135893253556960</title>\n<path fill=\"none\" stroke=\"black\" d=\"M967.5,-66.79C967.5,-60.07 967.5,-50.4 967.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"971,-41.19 967.5,-31.19 964,-41.19 971,-41.19\"/>\n</g>\n<!-- 135893647584384 -->\n<g id=\"node3\" class=\"node\">\n<title>135893647584384</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"888,-141 793,-141 793,-122 888,-122 888,-141\"/>\n<text text-anchor=\"middle\" x=\"840.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 135893647584384&#45;&gt;135893647581936 -->\n<g id=\"edge1\" class=\"edge\">\n<title>135893647584384&#45;&gt;135893647581936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M860.9,-121.98C881.52,-113.38 913.61,-99.99 937.19,-90.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"938.84,-93.25 946.72,-86.17 936.15,-86.79 938.84,-93.25\"/>\n</g>\n<!-- 135893647581024 -->\n<g id=\"node4\" class=\"node\">\n<title>135893647581024</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"905,-201.5 768,-201.5 768,-182.5 905,-182.5 905,-201.5\"/>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647581024&#45;&gt;135893647584384 -->\n<g id=\"edge2\" class=\"edge\">\n<title>135893647581024&#45;&gt;135893647584384</title>\n<path fill=\"none\" stroke=\"black\" d=\"M837.09,-182.37C837.65,-174.25 838.5,-161.81 839.21,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"842.72,-151.38 839.91,-141.17 835.73,-150.91 842.72,-151.38\"/>\n</g>\n<!-- 135893647586544 -->\n<g id=\"node5\" class=\"node\">\n<title>135893647586544</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"649,-262 560,-262 560,-243 649,-243 649,-262\"/>\n<text text-anchor=\"middle\" x=\"604.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">CatBackward0</text>\n</g>\n<!-- 135893647586544&#45;&gt;135893647581024 -->\n<g id=\"edge3\" class=\"edge\">\n<title>135893647586544&#45;&gt;135893647581024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M638.23,-242.99C679.13,-232.68 748.12,-215.28 792.98,-203.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"793.88,-207.36 802.72,-201.52 792.17,-200.57 793.88,-207.36\"/>\n</g>\n<!-- 135893647575936 -->\n<g id=\"node6\" class=\"node\">\n<title>135893647575936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"342,-322.5 247,-322.5 247,-303.5 342,-303.5 342,-322.5\"/>\n<text text-anchor=\"middle\" x=\"294.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 135893647575936&#45;&gt;135893647586544 -->\n<g id=\"edge4\" class=\"edge\">\n<title>135893647575936&#45;&gt;135893647586544</title>\n<path fill=\"none\" stroke=\"black\" d=\"M339.58,-303.49C395.3,-292.98 490.06,-275.1 549.86,-263.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"550.69,-267.22 559.87,-261.92 549.4,-260.34 550.69,-267.22\"/>\n</g>\n<!-- 135893647586640 -->\n<g id=\"node7\" class=\"node\">\n<title>135893647586640</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"268,-383 131,-383 131,-364 268,-364 268,-383\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647586640&#45;&gt;135893647575936 -->\n<g id=\"edge5\" class=\"edge\">\n<title>135893647586640&#45;&gt;135893647575936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M213.52,-363.87C228.81,-354.45 253.53,-339.23 271.64,-328.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"273.75,-330.89 280.42,-322.67 270.07,-324.93 273.75,-330.89\"/>\n</g>\n<!-- 135893647585920 -->\n<g id=\"node8\" class=\"node\">\n<title>135893647585920</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"122,-438 21,-438 21,-419 122,-419 122,-438\"/>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647585920&#45;&gt;135893647586640 -->\n<g id=\"edge6\" class=\"edge\">\n<title>135893647585920&#45;&gt;135893647586640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M92.07,-418.98C112.93,-410.34 145.47,-396.87 169.27,-387.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170.66,-390.23 178.56,-383.17 167.98,-383.76 170.66,-390.23\"/>\n</g>\n<!-- 135893253170544 -->\n<g id=\"node9\" class=\"node\">\n<title>135893253170544</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"125,-504 0,-504 0,-474 125,-474 125,-504\"/>\n<text text-anchor=\"middle\" x=\"62.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input1.weight</text>\n<text text-anchor=\"middle\" x=\"62.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64, 3, 9, 9)</text>\n</g>\n<!-- 135893253170544&#45;&gt;135893647585920 -->\n<g id=\"edge7\" class=\"edge\">\n<title>135893253170544&#45;&gt;135893647585920</title>\n<path fill=\"none\" stroke=\"black\" d=\"M64.68,-473.84C65.87,-466.13 67.35,-456.49 68.63,-448.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.09,-448.68 70.15,-438.27 65.17,-447.62 72.09,-448.68\"/>\n</g>\n<!-- 135893647576320 -->\n<g id=\"node10\" class=\"node\">\n<title>135893647576320</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"250,-438 149,-438 149,-419 250,-419 250,-438\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647576320&#45;&gt;135893647586640 -->\n<g id=\"edge8\" class=\"edge\">\n<title>135893647576320&#45;&gt;135893647586640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.5,-418.75C199.5,-411.8 199.5,-401.85 199.5,-393.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"203,-393.09 199.5,-383.09 196,-393.09 203,-393.09\"/>\n</g>\n<!-- 135893253172304 -->\n<g id=\"node11\" class=\"node\">\n<title>135893253172304</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"256,-504 143,-504 143,-474 256,-474 256,-504\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input1.bias</text>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n</g>\n<!-- 135893253172304&#45;&gt;135893647576320 -->\n<g id=\"edge9\" class=\"edge\">\n<title>135893253172304&#45;&gt;135893647576320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.5,-473.84C199.5,-466.21 199.5,-456.7 199.5,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"203,-448.27 199.5,-438.27 196,-448.27 203,-448.27\"/>\n</g>\n<!-- 135893647583520 -->\n<g id=\"node12\" class=\"node\">\n<title>135893647583520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"529,-322.5 434,-322.5 434,-303.5 529,-303.5 529,-322.5\"/>\n<text text-anchor=\"middle\" x=\"481.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 135893647583520&#45;&gt;135893647586544 -->\n<g id=\"edge10\" class=\"edge\">\n<title>135893647583520&#45;&gt;135893647586544</title>\n<path fill=\"none\" stroke=\"black\" d=\"M499.39,-303.49C519.88,-293.75 553.69,-277.66 577.42,-266.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"579.07,-269.47 586.59,-262.02 576.06,-263.15 579.07,-269.47\"/>\n</g>\n<!-- 135893647582176 -->\n<g id=\"node13\" class=\"node\">\n<title>135893647582176</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"529,-383 392,-383 392,-364 529,-364 529,-383\"/>\n<text text-anchor=\"middle\" x=\"460.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647582176&#45;&gt;135893647583520 -->\n<g id=\"edge11\" class=\"edge\">\n<title>135893647582176&#45;&gt;135893647583520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M463.6,-363.87C466.58,-355.57 471.17,-342.78 474.96,-332.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"478.3,-333.26 478.39,-322.67 471.72,-330.9 478.3,-333.26\"/>\n</g>\n<!-- 135893647585056 -->\n<g id=\"node14\" class=\"node\">\n<title>135893647585056</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"392,-438 291,-438 291,-419 392,-419 392,-438\"/>\n<text text-anchor=\"middle\" x=\"341.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647585056&#45;&gt;135893647582176 -->\n<g id=\"edge12\" class=\"edge\">\n<title>135893647585056&#45;&gt;135893647582176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M360.62,-418.98C379.85,-410.42 409.73,-397.11 431.81,-387.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"433.32,-390.44 441.03,-383.17 430.47,-384.04 433.32,-390.44\"/>\n</g>\n<!-- 135893253168864 -->\n<g id=\"node15\" class=\"node\">\n<title>135893253168864</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"399,-504 274,-504 274,-474 399,-474 399,-504\"/>\n<text text-anchor=\"middle\" x=\"336.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input2.weight</text>\n<text text-anchor=\"middle\" x=\"336.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64, 3, 3, 3)</text>\n</g>\n<!-- 135893253168864&#45;&gt;135893647585056 -->\n<g id=\"edge13\" class=\"edge\">\n<title>135893253168864&#45;&gt;135893647585056</title>\n<path fill=\"none\" stroke=\"black\" d=\"M337.71,-473.84C338.36,-466.21 339.17,-456.7 339.88,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"343.39,-448.53 340.75,-438.27 336.41,-447.93 343.39,-448.53\"/>\n</g>\n<!-- 135893647588704 -->\n<g id=\"node16\" class=\"node\">\n<title>135893647588704</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"520,-438 419,-438 419,-419 520,-419 520,-438\"/>\n<text text-anchor=\"middle\" x=\"469.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647588704&#45;&gt;135893647582176 -->\n<g id=\"edge14\" class=\"edge\">\n<title>135893647588704&#45;&gt;135893647582176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M468.01,-418.75C466.83,-411.8 465.14,-401.85 463.66,-393.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"467.08,-392.36 461.96,-383.09 460.18,-393.53 467.08,-392.36\"/>\n</g>\n<!-- 135893253173184 -->\n<g id=\"node17\" class=\"node\">\n<title>135893253173184</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"530,-504 417,-504 417,-474 530,-474 530,-504\"/>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input2.bias</text>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n</g>\n<!-- 135893253173184&#45;&gt;135893647588704 -->\n<g id=\"edge15\" class=\"edge\">\n<title>135893253173184&#45;&gt;135893647588704</title>\n<path fill=\"none\" stroke=\"black\" d=\"M472.53,-473.84C472.01,-466.21 471.36,-456.7 470.8,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"474.27,-448 470.1,-438.27 467.29,-448.48 474.27,-448\"/>\n</g>\n<!-- 135893647582080 -->\n<g id=\"node18\" class=\"node\">\n<title>135893647582080</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"652,-322.5 557,-322.5 557,-303.5 652,-303.5 652,-322.5\"/>\n<text text-anchor=\"middle\" x=\"604.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 135893647582080&#45;&gt;135893647586544 -->\n<g id=\"edge16\" class=\"edge\">\n<title>135893647582080&#45;&gt;135893647586544</title>\n<path fill=\"none\" stroke=\"black\" d=\"M604.5,-303.37C604.5,-295.25 604.5,-282.81 604.5,-272.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608,-272.17 604.5,-262.17 601,-272.17 608,-272.17\"/>\n</g>\n<!-- 135893647580208 -->\n<g id=\"node19\" class=\"node\">\n<title>135893647580208</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"684,-383 547,-383 547,-364 684,-364 684,-383\"/>\n<text text-anchor=\"middle\" x=\"615.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647580208&#45;&gt;135893647582080 -->\n<g id=\"edge17\" class=\"edge\">\n<title>135893647580208&#45;&gt;135893647582080</title>\n<path fill=\"none\" stroke=\"black\" d=\"M613.88,-363.87C612.33,-355.66 609.96,-343.04 607.99,-332.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"611.42,-331.85 606.13,-322.67 604.54,-333.14 611.42,-331.85\"/>\n</g>\n<!-- 135893647574784 -->\n<g id=\"node20\" class=\"node\">\n<title>135893647574784</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"664,-438 563,-438 563,-419 664,-419 664,-438\"/>\n<text text-anchor=\"middle\" x=\"613.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647574784&#45;&gt;135893647580208 -->\n<g id=\"edge18\" class=\"edge\">\n<title>135893647574784&#45;&gt;135893647580208</title>\n<path fill=\"none\" stroke=\"black\" d=\"M613.83,-418.75C614.09,-411.8 614.47,-401.85 614.8,-393.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"618.3,-393.21 615.18,-383.09 611.3,-392.95 618.3,-393.21\"/>\n</g>\n<!-- 135893253163904 -->\n<g id=\"node21\" class=\"node\">\n<title>135893253163904</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"673,-504 548,-504 548,-474 673,-474 673,-504\"/>\n<text text-anchor=\"middle\" x=\"610.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input3.weight</text>\n<text text-anchor=\"middle\" x=\"610.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64, 3, 5, 5)</text>\n</g>\n<!-- 135893253163904&#45;&gt;135893647574784 -->\n<g id=\"edge19\" class=\"edge\">\n<title>135893253163904&#45;&gt;135893647574784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M611.23,-473.84C611.62,-466.21 612.1,-456.7 612.53,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"616.03,-448.43 613.05,-438.27 609.04,-448.07 616.03,-448.43\"/>\n</g>\n<!-- 135893647575216 -->\n<g id=\"node22\" class=\"node\">\n<title>135893647575216</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"794,-438 693,-438 693,-419 794,-419 794,-438\"/>\n<text text-anchor=\"middle\" x=\"743.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647575216&#45;&gt;135893647580208 -->\n<g id=\"edge20\" class=\"edge\">\n<title>135893647575216&#45;&gt;135893647580208</title>\n<path fill=\"none\" stroke=\"black\" d=\"M722.93,-418.98C702.07,-410.34 669.53,-396.87 645.73,-387.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"647.02,-383.76 636.44,-383.17 644.34,-390.23 647.02,-383.76\"/>\n</g>\n<!-- 135893253169824 -->\n<g id=\"node23\" class=\"node\">\n<title>135893253169824</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"804,-504 691,-504 691,-474 804,-474 804,-504\"/>\n<text text-anchor=\"middle\" x=\"747.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input3.bias</text>\n<text text-anchor=\"middle\" x=\"747.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n</g>\n<!-- 135893253169824&#45;&gt;135893647575216 -->\n<g id=\"edge21\" class=\"edge\">\n<title>135893253169824&#45;&gt;135893647575216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M746.53,-473.84C746.01,-466.21 745.36,-456.7 744.8,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"748.27,-448 744.1,-438.27 741.29,-448.48 748.27,-448\"/>\n</g>\n<!-- 135893647583568 -->\n<g id=\"node24\" class=\"node\">\n<title>135893647583568</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"765,-322.5 670,-322.5 670,-303.5 765,-303.5 765,-322.5\"/>\n<text text-anchor=\"middle\" x=\"717.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 135893647583568&#45;&gt;135893647586544 -->\n<g id=\"edge22\" class=\"edge\">\n<title>135893647583568&#45;&gt;135893647586544</title>\n<path fill=\"none\" stroke=\"black\" d=\"M700.83,-303.37C682.22,-293.73 651.88,-278.03 630.22,-266.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"631.73,-263.66 621.24,-262.17 628.51,-269.87 631.73,-263.66\"/>\n</g>\n<!-- 135893647586016 -->\n<g id=\"node25\" class=\"node\">\n<title>135893647586016</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"953,-383 816,-383 816,-364 953,-364 953,-383\"/>\n<text text-anchor=\"middle\" x=\"884.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">ConvolutionBackward0</text>\n</g>\n<!-- 135893647586016&#45;&gt;135893647583568 -->\n<g id=\"edge23\" class=\"edge\">\n<title>135893647586016&#45;&gt;135893647583568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M860.22,-363.99C831.52,-353.94 783.61,-337.16 751.3,-325.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"752.41,-322.52 741.81,-322.52 750.09,-329.13 752.41,-322.52\"/>\n</g>\n<!-- 135893647581648 -->\n<g id=\"node26\" class=\"node\">\n<title>135893647581648</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"935,-438 834,-438 834,-419 935,-419 935,-438\"/>\n<text text-anchor=\"middle\" x=\"884.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647581648&#45;&gt;135893647586016 -->\n<g id=\"edge24\" class=\"edge\">\n<title>135893647581648&#45;&gt;135893647586016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M884.5,-418.75C884.5,-411.8 884.5,-401.85 884.5,-393.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"888,-393.09 884.5,-383.09 881,-393.09 888,-393.09\"/>\n</g>\n<!-- 135893253554320 -->\n<g id=\"node27\" class=\"node\">\n<title>135893253554320</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"947,-504 822,-504 822,-474 947,-474 947,-504\"/>\n<text text-anchor=\"middle\" x=\"884.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input4.weight</text>\n<text text-anchor=\"middle\" x=\"884.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64, 3, 7, 7)</text>\n</g>\n<!-- 135893253554320&#45;&gt;135893647581648 -->\n<g id=\"edge25\" class=\"edge\">\n<title>135893253554320&#45;&gt;135893647581648</title>\n<path fill=\"none\" stroke=\"black\" d=\"M884.5,-473.84C884.5,-466.21 884.5,-456.7 884.5,-448.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"888,-448.27 884.5,-438.27 881,-448.27 888,-448.27\"/>\n</g>\n<!-- 135893647580064 -->\n<g id=\"node28\" class=\"node\">\n<title>135893647580064</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1063,-438 962,-438 962,-419 1063,-419 1063,-438\"/>\n<text text-anchor=\"middle\" x=\"1012.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647580064&#45;&gt;135893647586016 -->\n<g id=\"edge26\" class=\"edge\">\n<title>135893647580064&#45;&gt;135893647586016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M991.93,-418.98C971.07,-410.34 938.53,-396.87 914.73,-387.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"916.02,-383.76 905.44,-383.17 913.34,-390.23 916.02,-383.76\"/>\n</g>\n<!-- 135893253554480 -->\n<g id=\"node29\" class=\"node\">\n<title>135893253554480</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"1078,-504 965,-504 965,-474 1078,-474 1078,-504\"/>\n<text text-anchor=\"middle\" x=\"1021.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">conv_input4.bias</text>\n<text text-anchor=\"middle\" x=\"1021.5\" y=\"-481\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n</g>\n<!-- 135893253554480&#45;&gt;135893647580064 -->\n<g id=\"edge27\" class=\"edge\">\n<title>135893253554480&#45;&gt;135893647580064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1019.32,-473.84C1018.13,-466.13 1016.65,-456.49 1015.37,-448.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1018.83,-447.62 1013.85,-438.27 1011.91,-448.68 1018.83,-447.62\"/>\n</g>\n<!-- 135893647579680 -->\n<g id=\"node30\" class=\"node\">\n<title>135893647579680</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"887,-262 786,-262 786,-243 887,-243 887,-262\"/>\n<text text-anchor=\"middle\" x=\"836.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647579680&#45;&gt;135893647581024 -->\n<g id=\"edge28\" class=\"edge\">\n<title>135893647579680&#45;&gt;135893647581024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M836.5,-242.87C836.5,-234.75 836.5,-222.31 836.5,-211.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"840,-211.67 836.5,-201.67 833,-211.67 840,-211.67\"/>\n</g>\n<!-- 135893253554640 -->\n<g id=\"node31\" class=\"node\">\n<title>135893253554640</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"896,-328 783,-328 783,-298 896,-298 896,-328\"/>\n<text text-anchor=\"middle\" x=\"839.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">conv2.weight</text>\n<text text-anchor=\"middle\" x=\"839.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (32, 256, 1, 1)</text>\n</g>\n<!-- 135893253554640&#45;&gt;135893647579680 -->\n<g id=\"edge29\" class=\"edge\">\n<title>135893253554640&#45;&gt;135893647579680</title>\n<path fill=\"none\" stroke=\"black\" d=\"M838.77,-297.84C838.38,-290.21 837.9,-280.7 837.47,-272.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"840.96,-272.07 836.95,-262.27 833.97,-272.43 840.96,-272.07\"/>\n</g>\n<!-- 135893647577616 -->\n<g id=\"node32\" class=\"node\">\n<title>135893647577616</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1006,-262 905,-262 905,-243 1006,-243 1006,-262\"/>\n<text text-anchor=\"middle\" x=\"955.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647577616&#45;&gt;135893647581024 -->\n<g id=\"edge30\" class=\"edge\">\n<title>135893647577616&#45;&gt;135893647581024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M938.2,-242.99C918.45,-233.29 885.95,-217.31 863.01,-206.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"864.34,-202.79 853.82,-201.52 861.25,-209.07 864.34,-202.79\"/>\n</g>\n<!-- 135893253554560 -->\n<g id=\"node33\" class=\"node\">\n<title>135893253554560</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"994,-328 917,-328 917,-298 994,-298 994,-328\"/>\n<text text-anchor=\"middle\" x=\"955.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">conv2.bias</text>\n<text text-anchor=\"middle\" x=\"955.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (32)</text>\n</g>\n<!-- 135893253554560&#45;&gt;135893647577616 -->\n<g id=\"edge31\" class=\"edge\">\n<title>135893253554560&#45;&gt;135893647577616</title>\n<path fill=\"none\" stroke=\"black\" d=\"M955.5,-297.84C955.5,-290.21 955.5,-280.7 955.5,-272.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"959,-272.27 955.5,-262.27 952,-272.27 959,-272.27\"/>\n</g>\n<!-- 135893647585968 -->\n<g id=\"node34\" class=\"node\">\n<title>135893647585968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1018,-141 917,-141 917,-122 1018,-122 1018,-141\"/>\n<text text-anchor=\"middle\" x=\"967.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647585968&#45;&gt;135893647581936 -->\n<g id=\"edge32\" class=\"edge\">\n<title>135893647585968&#45;&gt;135893647581936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M967.5,-121.75C967.5,-114.8 967.5,-104.85 967.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"971,-96.09 967.5,-86.09 964,-96.09 971,-96.09\"/>\n</g>\n<!-- 135893253554400 -->\n<g id=\"node35\" class=\"node\">\n<title>135893253554400</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"1024,-207 923,-207 923,-177 1024,-177 1024,-207\"/>\n<text text-anchor=\"middle\" x=\"973.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">conv3.weight</text>\n<text text-anchor=\"middle\" x=\"973.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (3, 32, 5, 5)</text>\n</g>\n<!-- 135893253554400&#45;&gt;135893647585968 -->\n<g id=\"edge33\" class=\"edge\">\n<title>135893253554400&#45;&gt;135893647585968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M972.05,-176.84C971.27,-169.21 970.29,-159.7 969.44,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"972.9,-150.86 968.4,-141.27 965.94,-151.57 972.9,-150.86\"/>\n</g>\n<!-- 135893647587456 -->\n<g id=\"node36\" class=\"node\">\n<title>135893647587456</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1137,-141 1036,-141 1036,-122 1137,-122 1137,-141\"/>\n<text text-anchor=\"middle\" x=\"1086.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135893647587456&#45;&gt;135893647581936 -->\n<g id=\"edge34\" class=\"edge\">\n<title>135893647587456&#45;&gt;135893647581936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1067.38,-121.98C1048.15,-113.42 1018.27,-100.11 996.19,-90.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"997.53,-87.04 986.97,-86.17 994.68,-93.44 997.53,-87.04\"/>\n</g>\n<!-- 135893253554800 -->\n<g id=\"node37\" class=\"node\">\n<title>135893253554800</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"1125,-207 1048,-207 1048,-177 1125,-177 1125,-207\"/>\n<text text-anchor=\"middle\" x=\"1086.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">conv3.bias</text>\n<text text-anchor=\"middle\" x=\"1086.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 135893253554800&#45;&gt;135893647587456 -->\n<g id=\"edge35\" class=\"edge\">\n<title>135893253554800&#45;&gt;135893647587456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1086.5,-176.84C1086.5,-169.21 1086.5,-159.7 1086.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090,-151.27 1086.5,-141.27 1083,-151.27 1090,-151.27\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7b9834974ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Loss Functions"
      ],
      "metadata": {
        "id": "1156c9EYy09V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Initialising the VGG model and printing its layers. This gives us information\n",
        " on which layer should we use for the perceptual loss.'''\n",
        "\n",
        "vgg = models.vgg19(pretrained=True).features.eval()\n",
        "vgg.to(device = 'cuda')\n",
        "summary(vgg, (3,32,32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rctvudPWlTCo",
        "outputId": "c7e19356-6674-4105-93f2-d39cada7f0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
            "              ReLU-4           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-18            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-19            [-1, 256, 4, 4]               0\n",
            "           Conv2d-20            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "           Conv2d-24            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-25            [-1, 512, 4, 4]               0\n",
            "           Conv2d-26            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
            "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-30            [-1, 512, 2, 2]               0\n",
            "           Conv2d-31            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-32            [-1, 512, 2, 2]               0\n",
            "           Conv2d-33            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-36            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-37            [-1, 512, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.86\n",
            "Params size (MB): 76.39\n",
            "Estimated Total Size (MB): 81.26\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Load pre-trained VGG-19 model without fully connected layers\n",
        "\n",
        " Includes some modifications made by Anirudh + Gugan. Swaps MSE loss for\n",
        " the VGG Perceptual Loss inspired from the SRGAN paper.\n",
        " ---\n",
        " Christian Ledig, Lucas Theis, Ferenc Husza ́r, Jose Caballero, Andrew\n",
        " Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz,\n",
        " Zehan Wang,Wenzhe Shi, \"Photo-Realistic Single Image Super-Resolution Using a\n",
        " Generative Adversarial Network Actions\", CVPR, 2017.\n",
        " ---\n",
        " '''\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        self.vgg = vgg\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        loss = 0\n",
        "        x_features = self.vgg[35](x)\n",
        "        y_features = self.vgg[35](y)\n",
        "        # Calculate Euclidean distance:\n",
        "        loss += torch.norm(x_features - y_features)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "QjyP34UMjIwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Functions"
      ],
      "metadata": {
        "id": "2Q1BbiJcy6ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  running_psnr = 0.0\n",
        "  for bi, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "    image_data = data[0].to(device)\n",
        "    label = data[0].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(image_data)\n",
        "    loss = criterion(outputs, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    batch_psnr = psnr(label, outputs)\n",
        "    running_psnr += batch_psnr\n",
        "\n",
        "  final_loss = running_loss/len(dataloader.dataset)\n",
        "  final_psnr = running_psnr/len(dataloader)\n",
        "  return final_loss, final_psnr\n",
        "\n",
        "def validate(model, dataloader, epoch, criterion, output_dir):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_psnr = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for bi, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "      image_data = data[0].to(device)\n",
        "      label = data[1].to(device)\n",
        "\n",
        "      outputs = model(image_data)\n",
        "      loss = criterion(outputs, label)\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      batch_psnr = psnr(label, outputs)\n",
        "      running_psnr += batch_psnr\n",
        "\n",
        "      # For saving the batch samples for the validation results\n",
        "      # every epoch.\n",
        "      if SAVE_VALIDATION_RESULTS and (epoch%10==0):\n",
        "        save_validation_results(outputs, epoch, bi, output_dir)\n",
        "\n",
        "    final_loss = running_loss/len(dataloader.dataset)\n",
        "    final_psnr = running_psnr/len(dataloader)\n",
        "    return final_loss, final_psnr"
      ],
      "metadata": {
        "id": "hFhzpxNOxRYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_training(model, epochs, optimizer, criterion, train_csv_file, valid_csv_file, output_dir):\n",
        "\n",
        "  dataset_train, dataset_valid = get_datasets(train_csv_file,valid_csv_file)\n",
        "\n",
        "  train_loader, valid_loader = get_dataloaders(dataset_train, dataset_valid)\n",
        "  print(f\"Training samples: {len(dataset_train)}\")\n",
        "  print(f\"Validation samples: {len(dataset_valid)}\")\n",
        "\n",
        "  train_loss, val_loss = [], []\n",
        "  train_psnr, val_psnr = [], []\n",
        "  start = time.time()\n",
        "  for epoch in range(epochs):\n",
        "    train_epoch_loss, train_epoch_psnr = train(model, train_loader, optimizer, criterion)\n",
        "    val_epoch_loss, val_epoch_psnr = validate(model, valid_loader, epoch+1, criterion, output_dir)\n",
        "    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n",
        "    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n",
        "\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_psnr.append(train_epoch_psnr)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_psnr.append(val_epoch_psnr)\n",
        "\n",
        "    # Save model with all information every 10 epochs. Can be used\n",
        "    # resuming training.\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        save_model(epoch, model, optimizer, criterion, output_dir)\n",
        "    # Save the model state dictionary only every epoch. Small size,\n",
        "    # can be used for inference.\n",
        "    save_model_state(model, output_dir)\n",
        "    # Save the PSNR and loss plots every epoch.\n",
        "    save_plot(train_loss, val_loss, train_psnr, val_psnr, output_dir)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f\"Finished training in: {((end-start)/60):.3f} minutes\")"
      ],
      "metadata": {
        "id": "whiF6nU_yAFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr = 0.001\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "SAVE_VALIDATION_RESULTS = True"
      ],
      "metadata": {
        "id": "7GvTNE2ez7Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Baseline SRCNN with MSE Loss"
      ],
      "metadata": {
        "id": "SiQcHWbaDCWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomConvLayer().to(device)\n",
        "summary(model,(3,32,32))\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_csv_file = '/content/train_data_5_Imgs_patched.csv'\n",
        "valid_csv_file = '/content/test_data_50_Imgs.csv'\n",
        "output_dir = 'output_SRCNN_MSE_loss'\n",
        "\n",
        "start_training(model, epochs, optimizer, criterion, train_csv_file, valid_csv_file, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce2c947-2102-4463-9bc0-af76e4d4bce7",
        "id": "7RYT5rbGxGUo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]          15,616\n",
            "            Conv2d-2           [-1, 32, 32, 32]           2,080\n",
            "            Conv2d-3            [-1, 3, 32, 32]           2,403\n",
            "================================================================\n",
            "Total params: 20,099\n",
            "Trainable params: 20,099\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.77\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 0.86\n",
            "----------------------------------------------------------------\n",
            "Training samples: 68400\n",
            "Validation samples: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:51<00:00,  5.18it/s]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 25.870\n",
            "Val PSNR: 29.400\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:52<00:00,  5.08it/s]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 33.217\n",
            "Val PSNR: 29.102\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:49<00:00,  5.36it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 35.446\n",
            "Val PSNR: 30.863\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:48<00:00,  5.56it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 36.673\n",
            "Val PSNR: 30.926\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:49<00:00,  5.44it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 37.298\n",
            "Val PSNR: 31.241\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:47<00:00,  5.59it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 38.608\n",
            "Val PSNR: 31.088\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:48<00:00,  5.50it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 39.388\n",
            "Val PSNR: 30.641\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:48<00:00,  5.55it/s]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 39.645\n",
            "Val PSNR: 31.371\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:48<00:00,  5.58it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 40.555\n",
            "Val PSNR: 31.627\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:49<00:00,  5.46it/s]\n",
            "100%|██████████| 50/50 [01:27<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 40.986\n",
            "Val PSNR: 31.781\n",
            "Saving model...\n",
            "Finished training in: 12.297 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/output_SRCNN_MSE_loss.zip' '/content/output_SRCNN_MSE_loss'"
      ],
      "metadata": {
        "id": "ItCrRRTDjnwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the SRCNN with VGG Based Perceptual Loss"
      ],
      "metadata": {
        "id": "Jbfqt7x8wP__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomConvLayer().to(device)\n",
        "summary(model,(3,32,32))\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = VGGPerceptualLoss()\n",
        "\n",
        "train_csv_file = '/content/train_data_5_Imgs_patched.csv'\n",
        "valid_csv_file = '/content/test_data_50_Imgs.csv'\n",
        "output_dir = 'output_SRCNN_VGG_loss'\n",
        "\n",
        "start_training(model, epochs, optimizer, criterion, train_csv_file, valid_csv_file, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cbfa69-373c-44e4-9cc6-f7e3d3af3b09",
        "id": "5_KgrrvUqMH-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]          15,616\n",
            "            Conv2d-2           [-1, 32, 32, 32]           2,080\n",
            "            Conv2d-3            [-1, 3, 32, 32]           2,403\n",
            "================================================================\n",
            "Total params: 20,099\n",
            "Trainable params: 20,099\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.77\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 0.86\n",
            "----------------------------------------------------------------\n",
            "Training samples: 68400\n",
            "Validation samples: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:53<00:00,  5.02it/s]\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 27.411\n",
            "Val PSNR: 29.314\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:52<00:00,  5.14it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 34.367\n",
            "Val PSNR: 29.474\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:51<00:00,  5.22it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 36.424\n",
            "Val PSNR: 30.902\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:49<00:00,  5.42it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 37.993\n",
            "Val PSNR: 29.794\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:52<00:00,  5.12it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 37.608\n",
            "Val PSNR: 30.727\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:50<00:00,  5.31it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 38.173\n",
            "Val PSNR: 31.454\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:50<00:00,  5.32it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 40.846\n",
            "Val PSNR: 31.319\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:50<00:00,  5.26it/s]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 38.973\n",
            "Val PSNR: 31.435\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:49<00:00,  5.36it/s]\n",
            "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 41.870\n",
            "Val PSNR: 30.636\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:50<00:00,  5.34it/s]\n",
            "100%|██████████| 50/50 [01:26<00:00,  1.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 41.583\n",
            "Val PSNR: 31.238\n",
            "Saving model...\n",
            "Finished training in: 12.559 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/output_SRCNN_VGG_loss.zip' '/content/output_SRCNN_VGG_loss'"
      ],
      "metadata": {
        "id": "AId-f7u2qw7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training SRCNN Model V2 with parallel input Convolutions and VGG Perceptual loss"
      ],
      "metadata": {
        "id": "lmTygjziweTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomConvLayer2().to(device)\n",
        "summary(model,(3,32,32))\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = VGGPerceptualLoss()\n",
        "\n",
        "train_csv_file = '/content/train_data_5_Imgs_patched.csv'\n",
        "valid_csv_file = '/content/test_data_50_Imgs.csv'\n",
        "output_dir = 'output_SRCNN_v2_VGG_loss'\n",
        "\n",
        "start_training(model, epochs, optimizer, criterion, train_csv_file, valid_csv_file, output_dir)"
      ],
      "metadata": {
        "id": "PxyD1WWo0vZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1aedf0-a70c-4fa7-b78e-e23dc1d75620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]          15,616\n",
            "            Conv2d-2           [-1, 64, 32, 32]           1,792\n",
            "            Conv2d-3           [-1, 64, 32, 32]           4,864\n",
            "            Conv2d-4           [-1, 64, 32, 32]           9,472\n",
            "            Conv2d-5           [-1, 32, 32, 32]           8,224\n",
            "            Conv2d-6            [-1, 3, 32, 32]           2,403\n",
            "================================================================\n",
            "Total params: 42,371\n",
            "Trainable params: 42,371\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.27\n",
            "Params size (MB): 0.16\n",
            "Estimated Total Size (MB): 2.45\n",
            "----------------------------------------------------------------\n",
            "Training samples: 68400\n",
            "Validation samples: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [01:03<00:00,  4.24it/s]\n",
            "100%|██████████| 50/50 [00:20<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 31.438\n",
            "Val PSNR: 30.003\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:58<00:00,  4.61it/s]\n",
            "100%|██████████| 50/50 [00:23<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 38.369\n",
            "Val PSNR: 31.351\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:59<00:00,  4.53it/s]\n",
            "100%|██████████| 50/50 [00:20<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 39.983\n",
            "Val PSNR: 31.392\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:57<00:00,  4.63it/s]\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 40.233\n",
            "Val PSNR: 31.537\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:58<00:00,  4.57it/s]\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 42.965\n",
            "Val PSNR: 31.681\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [01:03<00:00,  4.24it/s]\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 43.609\n",
            "Val PSNR: 30.952\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:57<00:00,  4.68it/s]\n",
            "100%|██████████| 50/50 [00:20<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 42.040\n",
            "Val PSNR: 31.554\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [00:57<00:00,  4.66it/s]\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 44.208\n",
            "Val PSNR: 31.586\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [01:04<00:00,  4.16it/s]\n",
            "100%|██████████| 50/50 [00:18<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 43.304\n",
            "Val PSNR: 31.512\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 268/268 [01:04<00:00,  4.13it/s]\n",
            "100%|██████████| 50/50 [01:39<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PSNR: 45.027\n",
            "Val PSNR: 31.673\n",
            "Saving model...\n",
            "Finished training in: 14.823 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/output_SRCNN_v2_VGG_loss.zip' '/content/output_SRCNN_v2_VGG_loss'"
      ],
      "metadata": {
        "id": "FV008zCxn8AW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}